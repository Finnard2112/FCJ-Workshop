[
{
	"uri": "/3-security-automation/3.1-configure-event-bridge/",
	"title": "Configuring EventBridge",
	"tags": [],
	"description": "",
	"content": "This sections walks through the process of editing your Amazon EventBridge rule to make it more specific. By default, the rule might be broad. This procedure will configure it to trigger your security workflow only for the specific types of finding.\nStep 1: Navigate to Amazon EventBridge In the AWS Management Console, type \u0026ldquo;EventBridge\u0026rdquo; in the search bar and select it.\nStep 2: Select Your Rule In the left-hand navigation pane, click on Rules. From the list of rules, select the one you created for this project (e.g., GuardDuty-Lambda-Threat-Listener). Step 3: Edit the Rule In the top-right corner of the rule\u0026rsquo;s detail page, click the Edit button.\nStep 4: Edit the Event Pattern On the \u0026ldquo;Edit rule\u0026rdquo; page, scroll down to the Event pattern section.\nClick the Edit pattern button. This will open an editor where you can modify the JSON that defines what the rule listens for.\nYou will now update the JSON pattern to filter for the specific finding type.\nOriginal Pattern (Broad):\n{ \u0026#34;source\u0026#34;: [\u0026#34;aws.guardduty\u0026#34;, \u0026#34;custom.test.guardduty\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;GuardDuty Finding\u0026#34;] } New Pattern (Specific): Replace the original pattern with the following JSON. This adds a detail block to match the specific type of the finding. For example, we will use UnauthorizedAccess:Lambda/TorRelay for now.\n{ \u0026#34;source\u0026#34;: [\u0026#34;aws.guardduty\u0026#34;, \u0026#34;custom.test.guardduty\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;GuardDuty Finding\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;type\u0026#34;: [\u0026#34;UnauthorizedAccess:Lambda/TorRelay\u0026#34;] } } Step 5: Save the Changes After pasting the new pattern, scroll to the bottom of the section and click Next. You do not need to change the target. Click Next again. On the final review page, click Update rule. Configuration Complete Your security automation workflow is now configured to only respond to the specific UnauthorizedAccess:Lambda/TorRelay threat, making your automation more precise.\n"
},
{
	"uri": "/2-prepare-environment/2.1-deploy-cloudformation/",
	"title": "Deploy using CloudFormation",
	"tags": [],
	"description": "",
	"content": "This guide provides step-by-step instructions for deploying the complete Security Automation platform using the AWS Management Console and a CloudFormation template.\nPrerequisites Before you begin, you will need:\nAn AWS Account with administrative permissions. The final IaC.yaml CloudFormation template file for this project, downloaded to your local machine. Step 1: Navigate to CloudFormation In the AWS Management Console, type \u0026ldquo;CloudFormation\u0026rdquo; into the search bar and select it. Ensure you are in your desired AWS Region. Step 2: Create the Stack From the CloudFormation dashboard, click the Create stack button. Select With new resources (standard). Step 3: Specify the Template Download the Infrastructure file from https://github.com/Finnard2112/Internship/blob/intern/Nguyen-Ha-Phan/project/IaC.yaml Under Prepare template, select Template is ready. Under Template source, select Upload a template file. Click Choose file and select the downloaded IaC.yaml file from your local machine. Click Next. Step 5: Specify Stack Details Stack name: Enter a unique name for your deployment (e.g., SecurityAutomationStack). There are no parameters to fill in for this template. Click Next. Step 6: Configure Stack Options You can leave all the options on this page as their defaults for this project.\nScroll to the bottom and click Next. Step 7: Review and Create This is the final review page.\nScroll to the very bottom to the Capabilities section. You must check the box that says: \u0026ldquo;I acknowledge that AWS CloudFormation might create IAM resources with custom names.\u0026rdquo; This is required because the template creates several IAM Roles and Policies. Click Create stack. The deployment process will now begin and may take 5-10 minutes. You can monitor its progress in the Events tab. The status will show CREATE_COMPLETE when finished.\n"
},
{
	"uri": "/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Content:\n📌 Project Goals 💡 Purpose and Applications 📌 Project Goals This project aims to implement a completely automated security incident response on AWS using core services such as GuardDuty, EventBridge, and Lambdas. The entire workflow will be automated to ensure the lowest possible Mean Time To Respond (MTTR) and preserving evidence\n💡 Purpose and Applications Help businesses reduce their MTTR and help forensics by collecting evidence Enhance practical skills with real AWS services. Serve as a foundation for expanding into creating a more complete incident response system "
},
{
	"uri": "/",
	"title": "Security Incident Response with Forensics Integration",
	"tags": [],
	"description": "",
	"content": "Automating Security Incident Response with Forensics Integration Overall In this lab, you\u0026rsquo;ll build a serverless application and learn to protect it by implementing a fully automated incident response system to contain the threat, collect related evidence, create a timeline analysis, and generate a report. The report will then be sent to the subscribed emails. You will implement this using Lambda, EventBridge, StepFunctions, and Amazon SNS\nWorkshop Goals Understand serverless application architecture on AWS Detect threats with GuardDuty Trigger response using EventBridge Create workflows with Amazon StepFunctions Contain, collect evidence, timeline analysis, and generate reports with Lambdas Send reports through email with SNS Content Introduction Preparation "
},
{
	"uri": "/2-prepare-environment/2.2-configuring-application/",
	"title": "Configuring the Serverless Aplication",
	"tags": [],
	"description": "",
	"content": "After your CloudFormation stack has been successfully created, there are a few essential configuration steps you must complete manually to make the platform fully operational.\n1. Adding Code to Your Lambda Functions The CloudFormation template deployed all seven of your Lambda functions with simple placeholder code. You now need to upload the actual application and security logic for each one.\nPrepare Your Code: For each of your seven Lambda functions, visit the following link to download the lambda code and see additional instructions for configuration https://github.com/Finnard2112/Internship/tree/intern/Nguyen-Ha-Phan/project/lambdas\nNavigate to the Lambda Console: In the AWS Management Console, go to the Lambda service.\nFind Your Functions: You will see a list of the functions created by your stack, such as:\nSecurityAutomationStack-ProductService SecurityAutomationStack-ScanService SecurityAutomationStack-RemoveProduct SecurityAutomationStack-ContainmentLambda SecurityAutomationStack-EvidenceCollectionLambda SecurityAutomationStack-TimelineAnalysisLambda SecurityAutomationStack-GenerateReportLambda Upload the Code: For each of the seven functions, perform the following steps: Click on the function\u0026rsquo;s name. In the Code source section, copy and paste the previously downloaded code into this section. Change the file name to lambda_function.py Click Deploy. Repeat this upload process for all seven functions, ensuring you upload the correct code package to each one. 2. Create a Test User in Cognito To test your application\u0026rsquo;s API endpoints (like adding or removing a product), you need to authenticate as a real user. This step walks you through creating a test user in your new Cognito User Pool using the AWS CLI.\nFor more information on AWS CLI, visit this link: https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html\nGet Your User Pool and Client IDs: Open your terminal. You need to get two values from your CloudFormation stack\u0026rsquo;s outputs. Replace YourStackName with the name you gave your stack (e.g., SecurityAutomationStack). # Get the User Pool ID USER_POOL_ID=$(aws cloudformation describe-stacks --stack-name YourStackName --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;UserPoolId\u0026#39;].OutputValue\u0026#34; --output text) # Get the User Pool Client ID USER_CLIENT_ID=$(aws cloudformation describe-stacks --stack-name YourStackName --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;UserPoolClientId\u0026#39;].OutputValue\u0026#34; --output text) Sign Up a New User: Run the following command, replacing \u0026lt;test-email@example.com\u0026gt; and \u0026lt;YourStrongPassword!123\u0026gt; with your desired credentials. aws cognito-idp sign-up \\ --client-id $USER_CLIENT_ID \\ --username \u0026lt;test-email@example.com\u0026gt; \\ --password \u0026lt;YourStrongPassword!123\u0026gt; \\ --user-attributes Name=\u0026#34;email\u0026#34;,Value=\u0026#34;\u0026lt;test-email@example.com\u0026gt;\u0026#34; Confirm the User as an Admin:\nBy default, a new user must confirm their email. For testing, you can confirm them immediately as an administrator. Run the following command, using the same email address as before. aws cognito-idp admin-confirm-sign-up \\ --user-pool-id $USER_POOL_ID \\ --username \u0026lt;test-email@example.com\u0026gt; Your user is now active and can sign in.\nConfirm the User doesn\u0026rsquo;t need to change passwords:\nIf in the console, your User has its status set to FORCE_CHANGE_PASSWORD, run the following command --user-pool-id \u0026lt;your-user-pool-id\u0026gt; \\ --username \u0026lt;username\u0026gt; \\ --password \u0026lt;password\u0026gt; \\ --permanent Configuration Complete Once you have uploaded all your Lambda function code and configured the Cognito user pool,.\n"
},
{
	"uri": "/3-security-automation/3.2-prepare-test-event/",
	"title": "Prepare Test Event",
	"tags": [],
	"description": "",
	"content": "To accurately test our security automation workflow, we need a realistic event payload. This guide walks through the process of generating sample threat detections in AWS GuardDuty, finding a specific event, and customizing it to target a real Lambda function in our account.\nStep 1: Generate Sample Findings in GuardDuty First, we will have GuardDuty create a set of safe, mock threat detections.\nNavigate to the AWS GuardDuty console. In the left-hand navigation menu, click on Settings. Scroll down to the Sample findings section and click the Generate sample findings button. This will create a variety of different finding types in your account that you can use for testing.\nStep 2: Find and Copy the TorRelay Finding JSON Next, we\u0026rsquo;ll locate the specific finding we want to use as a template and copy its raw JSON data.\nIn the GuardDuty console, click on Findings in the left menu. In the filter bar at the top, search for the finding type: UnauthorizedAccess:Lambda/TorRelay. Click on the resulting finding to open the details pane on the right. Click on the Hyperlinked text for Finding ID. A new window will appear with the full JSON of the finding. Copy the entire content to your clipboard or a text editor. Step 3: Modify the JSON to Target Your Lambda Finally, we will edit the copied JSON to replace the placeholder resource with one of your actual Lambda functions.\nPaste the JSON you copied into a text editor. Locate the functionArn key, which is nested inside detail.resource.lambdaDetails. Navigate to the AWS Lambda console in a new tab and find one of your application functions (e.g., YourStackName-ProductService). Copy its full ARN. Go back to your text editor and replace the value of functionArn with the real ARN you just copied. Before (Original JSON from GuardDuty):\n\u0026#34;lambdaDetails\u0026#34;: { \u0026#34;functionArn\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:123456789012:function:GeneratedExampleFunction\u0026#34;, ... } After (Modified):\n\u0026#34;lambdaDetails\u0026#34;: { \u0026#34;functionArn\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:\u0026lt;YOUR_ACCOUNT_ID\u0026gt;:function:YourStackName-ProductService\u0026#34;, ... } Step 4: Modify the JSON\u0026rsquo;s source Locate the source key. Edit it to \u0026quot;custom.test.guardduty\u0026quot; Ready for Testing You now have a customized, realistic test event payload. You will use this modified JSON in the next step to manually trigger your EventBridge rule and test the entire security automation workflow.\n"
},
{
	"uri": "/2-prepare-environment/",
	"title": "Prepare the Environment",
	"tags": [],
	"description": "",
	"content": "Preparation Overview Before deploying the security automation system, you need to prepare essential AWS resources and configure them.\nContents: 2.1 Deploy using CloudFormation 2.2 Configuring the Serverless Application 2.3 Testing the Underlying Application 1. Deploy on CloudFormation Generate the necessary resources and configure them automatically using CloudFormation.\n2. Configuring the Serverless Application Add the necessary permissions and code for the serverless Lambda functions. Creating a Cognito user for the Gateway Authorizer\n3. Testing the Application Using the provided Python functions to interact with AWS\u0026rsquo;s REST API Gateway for CRUD operations\n"
},
{
	"uri": "/1-introduction/1.1-project-goals/",
	"title": "Project Goals",
	"tags": [],
	"description": "",
	"content": "Content:\n🎯 General Objective ⏱️ Specific Objectives 1. Reduce Mean Time to Respond (MTTR) 2. Automate Forensic Evidence Collection 3. Ensure Consistent and Repeatable Responses 🎯 General Objective The primary goal of this project is to design, build, and deploy a robust, event-driven platform on AWS that automates the end-to-end security incident response lifecycle. This system will transition our security operations from a slow, manual, and reactive model to a proactive, consistent, and near-instantaneous automated model.\n⏱️ Specific Objectives To achieve our general objective, we will focus on the following specific and measurable goals.\n1. Reduce Mean Time to Respond (MTTR) Decrease the MTTR for critical Lambda-based security threats from the standard baseline of 4-6 hours to under 60 seconds. This will be achieved by creating a fully automated workflow that handles threat detection, containment, and initial investigation without requiring human intervention.\n2. Automate Forensic Evidence Collection Implement an automated process to collect a comprehensive set of forensic evidence for every triggered incident. The collected artifacts will be stored securely in an immutable S3 bucket and will include:\nThe compromised function\u0026rsquo;s source code and configuration. A detailed snapshot of the function\u0026rsquo;s IAM role and all attached policies. Recent CloudWatch log entries. A chronological timeline analysis of related API calls from AWS CloudTrail. 3. Ensure Consistent and Repeatable Responses Codify our incident response procedures into an AWS Step Functions state machine. This ensures that every response to a specific threat type follows the exact same pre-approved, best-practice runbook, eliminating human error and variability.\n"
},
{
	"uri": "/3-security-automation/",
	"title": "Configuring the Security Automation",
	"tags": [],
	"description": "",
	"content": "Preparation Overview Before we fully deploy the security automation pipeline, we need to configure a few things\nContents: 3.1 Configuring EventBridge 3.2 Preparing the test event 3.3 Setting up the security automation 3.4 Testing the security automation pipeline 1 Configuring EventBridge Editing your Amazon EventBridge rule to make it more specific. This procedure will configure it to trigger your security workflow only for the specific types of finding.\n2. Preparing the test event Generate sample threat detections in AWS GuardDuty, finding a specific event, and customizing it to target a real Lambda function in our account.\n3. Setting up the security automation Set up an Athena CloudTrail table, SNS subscription, and Timeline Analysis Lambda\n4. Testing the security automation pipeline Use sample threat event to trigger our security automation pipeline, verifying each components.\n"
},
{
	"uri": "/1-introduction/1.2-purpose-and-applications/",
	"title": "Purpose and Applications",
	"tags": [],
	"description": "",
	"content": "This section details the rationale for building the security automation platform on AWS, outlines practical use cases, and explores future scalability.\nContent:\n🌐 Why use AWS for automated incident response? 📌 Applicable Use Cases 🚀 Future Scalability 🌐 Why use AWS for automated incident response? Building a security automation platform with native AWS serverless services offers distinct advantages over traditional, on-premise, or third-party solutions.\nSpeed through Event-Driven Architecture: The entire platform is built on an event-driven model. Services like AWS GuardDuty generate findings as events, which are immediately captured by Amazon EventBridge. This allows for a near-instantaneous response—measured in seconds—that is impossible to achieve with traditional systems that rely on polling or periodic checks.\nDeep Integration and Context: The security tools are deeply integrated with the infrastructure they protect. A GuardDuty finding doesn\u0026rsquo;t just say \u0026ldquo;something is wrong\u0026rdquo;; it provides rich, contextual data, including the specific ARN of the compromised resource. This allows our Lambda functions to perform highly targeted, precise actions, such as isolating the exact Lambda function or EC2 instance without affecting other services.\nExtreme Cost-Effectiveness: The serverless \u0026ldquo;pay-per-incident\u0026rdquo; model is exceptionally economical. There are no idle servers or ongoing software licenses for the response workflow. The platform costs virtually nothing when dormant and only incurs micro-charges for the few seconds it runs in response to a threat.\nProgrammable and Auditable Responses: By defining the entire incident response plan as code (AWS Lambda, Step Functions, and CloudFormation), we create a version-controlled, auditable, and repeatable \u0026ldquo;runbook.\u0026rdquo; This ensures that our responses are consistent and compliant, eliminating the risk of human error during high-stress situations.\n📌 Applicable Use Cases While this project focuses on a playbook for compromised Lambda functions, the framework is designed to handle a wide variety of security events across AWS. Applicable use cases include:\nCompromised Compute Resources:\nLambda Function: A GuardDuty finding for a Lambda function triggers immediate IAM role containment, evidence collection, and timeline analysis (the core use case of this project). EC2 Instance: A finding for an EC2 instance communicating with a cryptocurrency mining server can trigger a workflow that automatically isolates the instance by attaching a \u0026ldquo;quarantine\u0026rdquo; security group that denies all traffic. Data Security Events:\nExposed S3 Buckets: A CloudTrail event indicating that a public access block has been removed from a critical S3 bucket can trigger a Lambda that immediately reapplies the block and alerts the security team. Identity and Access Management (IAM) Threats:\nLeaked Access Keys: A finding that an IAM user\u0026rsquo;s access key is being used from an unusual geographic location can trigger a Lambda to automatically deactivate that key, preventing further unauthorized access. 🚀 Future Scalability The platform is designed to be a scalable foundation for our security operations. Future enhancements can include:\nExpanding the Playbook Library: The core framework (EventBridge, Step Functions) makes it easy to add new rules and response Lambdas to handle dozens of other finding types without re-architecting the system. New playbooks can be developed and plugged in as modular components.\nThird-Party Integrations: The workflow can be extended to integrate with external tools. For example, a Step Function state could be added to automatically:\nCreate a high-priority ticket in Jira or ServiceNow. Post a detailed, formatted alert to a Slack channel. Send structured log data to a SIEM like Splunk for advanced correlation. \u0026ldquo;Human-in-the-Loop\u0026rdquo; Workflows: For actions on highly sensitive production resources, the Step Function can be modified to pause and wait for human approval. It can send an email with \u0026ldquo;Approve\u0026rdquo; or \u0026ldquo;Deny\u0026rdquo; links, only proceeding with the containment action after an authorized analyst gives consent.\nPredictive Security: The S3 evidence locker will accumulate a rich, structured dataset of all security incidents. Over time, this data can be used to train machine learning models to identify attack patterns, predict future threats, and move from a reactive to a predictive security posture.\n"
},
{
	"uri": "/3-security-automation/3.3-setting-up-automation/",
	"title": "Setting up security automation",
	"tags": [],
	"description": "",
	"content": "We need to set up a few more components for our security automation pipeline\n1. Create Athena Table The TimelineAnalysisLambda needs a table in Athena to query your CloudTrail logs. You must create this manually.\nGo to the Amazon Athena console. Follow the steps in the AWS Documentation to create a table from the logs in your new CloudTrailBucket. The bucket\u0026rsquo;s name is available in the Outputs tab of your CloudFormation stack. Note: Choose \u0026lt;Stack Name\u0026gt;-cloudtrailbucket-abcdefgh when asked where to set up your Athena Table 2. Edit Timeline Analysis Once you have created the Athena Table, note the resulting table name and go to TimelineAnalysisLambda\nGo to the Amazon Lambda console. Go to TimelineAnalysisLambda. Click on Configuration and Environment Variables Click on Edit and add a new variable named ATHENA_TABLE_NAME Fill in the table name of the Athena table you created for step 1 3. SNS Subscription Head over to the SNS service for Amazon and click on the Topic that is associated with the CloudFormation stack. Click on \u0026ldquo;Create Subscription\u0026rdquo; and enter your email. Confirm the subscription once the confirmation arrive at your email to receive incident reports\nReady for Testing Now, everything is set and ready. You can move on to the next section to test our security pipeline\n"
},
{
	"uri": "/2-prepare-environment/2.3-test-application/",
	"title": "Testing the Underlying Application",
	"tags": [],
	"description": "",
	"content": "We will test the underlying application before further implementing security automations to protect it. The API Gateway is authorized by a Cognito User Pool and GuardDuty at this point.\nPrerequisites Before you begin, ensure you have:\nPython 3 installed on your machine. The Boto3 and Requests Python libraries installed. If not, run: pip install boto3 requests Download the testing file from the following link: https://github.com/Finnard2112/Internship/tree/intern/Nguyen-Ha-Phan/project/Application_Tests.py Information related to the test user you created Step 1: Configure the Test Script Open the Application_Tests.py script in a code editor and update the constants at the top of the file to match your deployed environment.\nUSER_POOL_ID and CLIENT_ID: Replace the placeholder values with the UserPoolId and UserPoolClientId from your CloudFormation stack\u0026rsquo;s Outputs tab or Cognito\u0026rsquo;s console.\nREGION: Ensure this matches the AWS Region where you deployed your stack.\nUSERNAME and PASSWORD: Update these with the credentials of the test user you created in Cognito.\nAPI_URL: Replace the placeholder URL with the ApiUrl from your CloudFormation stack\u0026rsquo;s Outputs tab. Make sure it points to the correct resource (e.g., \u0026hellip;/prod/products).\nExample Configuration:\nUSER_POOL_ID = \u0026#34;us-east-1_xxxxxxxxx\u0026#34; CLIENT_ID = \u0026#34;xxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34; REGION = \u0026#34;us-east-1\u0026#34; USERNAME = \u0026#34;your-test-user@example.com\u0026#34; PASSWORD = \u0026#34;YourStrongPassword!123\u0026#34; API_URL = \u0026#34;[https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/prod/products](https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/prod/products)\u0026#34; Step 2: Running the Tests The Python script is organized into functions that test different parts of your API. The main execution block at the bottom of the script controls which test is run.\nA. Test Authentication (get_cognito_tokens) This function authenticates with Cognito using the provided username and password to retrieve JWT tokens. This is the first step for all other tests.\nB. Test Fetching Products (get_products) This is the default test run by the script. It uses the ID token from Cognito to make an authorized GET request to your /products endpoint.\nMake sure that api_response = get_products(tokens[\u0026quot;IdToken\u0026quot;]) on line 138 To Run: Execute the script from your terminal without any changes. python Application_Tests.py Expected Output: You will see a \u0026ldquo;✅ API Call Successful!\u0026rdquo; message and a JSON response containing a list of products (which will be empty initially).\\\nC. Test Creating a Product (create_product) This function sends an authorized POST request with a sample product payload to create a new item in your DynamoDB table.\nMake sure that api_response = create_product(tokens[\u0026quot;IdToken\u0026quot;]) on line 138 To Run: Execute the script from your terminal with the following changes. python Application_Tests.py Expected Output: A success message and a JSON response confirming the product was created, which may include the new productId. Note the productId\nD. Test Deleting a Product (delete_product) This function sends an authorized DELETE request to remove a product. It requires a valid productId.\nMake sure that api_response = create_product(tokens[\u0026quot;IdToken\u0026quot;], product_id_to_delete) on line 138 Replace product_id_to_delete with the actual product_id you noted To Run: Execute the script from your terminal with the following changes. python Application_Tests.py Expected Output: A success message and a JSON response confirming the deletion.\nBy following these steps, you can thoroughly test the authentication and core CRUD (Create, Read, Update, Delete) functionality of the underlying serverless application.\n"
},
{
	"uri": "/1-introduction/1.3-in-depth-design/",
	"title": "In Depth Design",
	"tags": [],
	"description": "",
	"content": "This document provides a detailed breakdown of the two main components of this project: the core serverless application and the automated security pipeline that protects it.\nContent:\n🏗️ Core Application Architecture Component Breakdown Typical Request Flow 🛡️ Automated Security Pipeline The Incident Response Lifecycle 🏗️ Core Application Architecture The underlying application is a modern, serverless e-commerce backend built entirely on managed AWS services. This design ensures high availability, automatic scaling, and cost-efficiency by eliminating the need for traditional server management.\nComponent Breakdown Amazon API Gateway: This is the \u0026ldquo;front door\u0026rdquo; for all incoming client requests. It manages API endpoints (e.g., /products), handles request routing, and is responsible for initial request validation and authorization. AWS Cognito: A secure, managed user identity service. It integrates directly with API Gateway to handle all user authentication (sign-up and sign-in) and provides authorization by issuing JWT tokens that must be included in every API request. AWS Lambda (Application Layer): These are the microservices that contain the business logic. Each function is responsible for a specific task: ProductService: Handles creating new products. ScanService: Handles retrieving a list of all products. RemoveProduct: Handles deleting a specific product. Amazon DynamoDB: A fully managed NoSQL database that serves as the persistent data store for the application. It holds all product information and is accessed directly by the Lambda functions. Typical Request Flow (Creating a Product) A registered user signs in via the client application, receiving a JWT token from Cognito. The client sends a POST request to the /products endpoint on API Gateway, including the JWT token in the Authorization header. API Gateway uses its Cognito authorizer to validate the token. If the token is valid, API Gateway forwards the request to the ProductService Lambda function. The ProductService Lambda executes its logic, validates the input, and writes the new product data to the DynamoDB table. A success response is returned through the same path to the client. 🛡️ Automated Security Pipeline The security pipeline is an event-driven workflow designed to automatically detect, contain, investigate, and report on security threats within the AWS account, requiring zero human intervention for the initial response.\nThe Incident Response Lifecycle The pipeline operates as a five-stage automated runbook, orchestrated by AWS Step Functions.\n1. Detection Service: AWS GuardDuty Role: GuardDuty is the threat detection engine. It continuously monitors AWS log sources (like CloudTrail and VPC Flow Logs) for malicious or unauthorized behavior. When it identifies a potential threat, such as a Lambda function communicating with a malicious IP, it generates a finding. 2. Trigger Service: Amazon EventBridge Role: EventBridge acts as the central nervous system. It has a rule configured to listen for specific findings from GuardDuty. When a finding matches the rule\u0026rsquo;s pattern, EventBridge immediately triggers the Step Functions state machine to begin the response. 3. Orchestration \u0026amp; Response Service: AWS Step Functions \u0026amp; AWS Lambda Role: The Step Functions state machine executes the pre-defined, multi-step incident response plan. Each step is a dedicated Lambda function. Containment (ContainmentLambda): The first action is to immediately stop the potential threat. This function gets the ARN of the compromised Lambda from the GuardDuty finding and attaches a restrictive IAM \u0026ldquo;deny-all\u0026rdquo; policy to its role, revoking its permissions to do anything else. MTTR: \u0026lt; 60 seconds. Evidence Collection (EvidenceCollectionLambda): This function acts as a digital forensics expert. It collects a snapshot of the compromised function\u0026rsquo;s state, including its source code, configuration, Lambda Layers, and a detailed breakdown of its IAM role and policies. All evidence is saved to a secure S3 bucket. Timeline Analysis (TimelineAnalysisLambda): This function automates the work of an investigator. It uses Amazon Athena to automatically query AWS CloudTrail logs for all API activity performed by the compromised function\u0026rsquo;s role around the time of the incident, creating a clear timeline of events. Reporting (GenerateReportLambda): This function acts as a security analyst. It reads all the collected evidence (configuration, IAM policies, logs, and timeline) from S3 and compiles a single, human-readable report. Notification (Amazon SNS): The final state of the Step Function takes the formatted report and publishes it to an Amazon SNS topic, which then sends it to subscribers (e.g., via email) to alert the human security team of the threat and the automated actions that were taken. By the time a human analyst sees the notification, the threat has already been contained, and a complete folder of evidence and a summary report are ready for their review.\n"
},
{
	"uri": "/3-security-automation/3.4-testing-security-pipeline/",
	"title": "Testing the security pipeline",
	"tags": [],
	"description": "",
	"content": "This guide provides the final end-to-end test for your security automation pipeline. We will manually send a crafted test event to the Amazon EventBridge event bus to simulate a threat detection, which will trigger your entire Step Functions workflow.\nStep 1: Prepare the Test Event Payload Copy the JSON template from 3.2 From following section 3.2, you should have a sample GuardDuty UnauthorizedAccess:Lambda/TorRelay finding.\nStep 2: Send the event through EventBridge Navigate to the Amazon EventBridge console. In the left menu, go to Event buses. Select the default event bus. In the top right, click the Send events button. Fill out the form with the following details: Event source: custom.test.guardduty Detail type: GuardDuty Finding Event detail: Paste the detail field\u0026rsquo;s value from the payload\u0026rsquo;s JSON here Click Send. Step 3: Verify the success of the pipeline After sending the event, the entire workflow should execute within about a minute. To confirm success, check the following:\n✅ Step Function Execution: Navigate to the Step Functions console. Look for a new execution of your state machine with a \u0026ldquo;Succeeded\u0026rdquo; status. You can click on it to see the visual graph of the successful workflow. ✅ SNS Notification: Check your email for the formatted incident report sent from your SNS topic. ✅ IAM Containment: Go to the IAM console and inspect the role of the Lambda you targeted (e.g., ProductService). The IncidentResponseDenyAllPolicy should now be attached. ✅ S3 Evidence: Navigate to your secure S3 evidence bucket. A new folder should exist, named after the finding ID, containing all the collected forensic artifacts (configuration.json, iam_permissions.json, timeline_analysis.json, etc.). If you can verify all these results, your security automation pipeline is fully configured and operational.\n"
},
{
	"uri": "/4-cleanup/",
	"title": "Project Cleanup Guide",
	"tags": [],
	"description": "",
	"content": "This guide provides the steps to safely and completely remove all AWS resources created for this project. Following these instructions will ensure that you do not incur any ongoing costs. The primary method for cleanup is deleting the CloudFormation stack, which manages the entire lifecycle of our infrastructure.\nContent:\nStep 1: Empty the S3 Buckets (Prerequisite) Step 2: Delete the Main CloudFormation Stack Step 3: Clean Up Remaining Resources Step 1: Empty the S3 Buckets (Prerequisite) 🗑️ Before you can delete the CloudFormation stack, you must manually empty the S3 buckets it created. CloudFormation cannot delete buckets that contain files.\nFind Your Bucket Names: Navigate to the CloudFormation console, select your stack (e.g., SecurityAutomationStack), and go to the Outputs tab. Note the names of the EvidenceBucketName, CloudTrailBucketName, and AthenaResultsBucketName.\nNavigate to S3: Go to the Amazon S3 console.\nEmpty Each Bucket: For each of the three buckets identified in step 1, perform the following actions:\nClick on the bucket name. Select all the files and folders inside. Click the Delete button. Type permanently delete into the confirmation box and click Delete objects. Step 2: Delete the Main CloudFormation Stack 🚀 This single action will automatically remove the vast majority of your project\u0026rsquo;s resources in the correct order.\nNavigate to CloudFormation: Go back to the CloudFormation console. Select the Stack: Make sure your project\u0026rsquo;s stack is selected. Delete the Stack: Click the Delete button. You will be asked to confirm the deletion. CloudFormation will now begin the deletion process, which can take several minutes. It will remove the Lambda functions, Step Function, API Gateway, IAM roles, and most other resources.\nStep 3: Clean Up Remaining Resources 🧹 A few resources will not be deleted by the stack, either by design or because they were created manually. You must remove these yourself to complete the cleanup.\nS3 Buckets: Your EvidenceBucket and CloudTrailBucket were configured with a DeletionPolicy: Retain as a safety measure.\nAction: Go back to the S3 console. Now that the buckets are empty and the stack is deleted, you can select these two buckets and delete them. Athena Table: The Athena table used to query CloudTrail logs was created manually, so CloudFormation does not manage it.\nAction: Go to the Amazon Athena console. In the Query Editor, run the following command, replacing your_cloudtrail_table_name with the name you used: DROP TABLE your_cloudtrail_table_name; CloudWatch Log Groups (Optional): The log groups for your Lambda functions are not deleted by default. They don\u0026rsquo;t typically incur costs and will expire based on their retention settings.\nAction: For a perfectly clean account, you can go to the CloudWatch console, select Log groups, and manually delete the log groups associated with your project\u0026rsquo;s Lambda functions. Once these steps are complete, all resources for your project will have been successfully removed.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]